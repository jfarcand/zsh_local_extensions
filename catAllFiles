#!/usr/bin/env bash

# -----------------------------------------------------------------------------
# catAllFiles: Calls catFiles on all base names found in directories.
# -----------------------------------------------------------------------------
# Usage:
#   catAllFiles [--withSchema schema.prisma] [--scanDir <dir>] [--outDir <dir>] 
#               [--extra dir1,dir2,...] [--watch] <dir1> <dir2> <dir3> ...
#
# Options:
#   --withSchema schema.prisma    Schema file to use for model lookups (case-insensitive)
#   --scanDir <dir>               Directory to scan for base names (defaults to first directory)
#   --outDir <dir>                Where to save output files (defaults to ~/Downloads)
#   --extra dir1,dir2,...         Comma-separated list of directories to search for related files
#   --watch                       Watch directories for changes and reprocess files
#
# Example:
#   catAllFiles --withSchema prisma/schema.prisma --extra services/api/graphql/queries,services/api/graphql/mutations --watch prisma/seeds src/resolvers/
# -----------------------------------------------------------------------------

# Process arguments
SCHEMA_FILE=""
SCAN_DIR=""
OUTPUT_DIR=~/Downloads
WATCH_MODE=false
DIRECTORIES=()
EXTRA_DIRS=""

while [[ $# -gt 0 ]]; do
    case "$1" in
        --withSchema)
            SCHEMA_FILE="$2"
            if [ ! -f "$SCHEMA_FILE" ]; then
                echo "Error: Schema file '$SCHEMA_FILE' not found"
                exit 1
            fi
            shift 2
            ;;
        --scanDir)
            SCAN_DIR="$2"
            if [ ! -d "$SCAN_DIR" ]; then
                echo "Error: Scan directory '$SCAN_DIR' not found"
                exit 1
            fi
            shift 2
            ;;
        --outDir)
            OUTPUT_DIR="$2"
            shift 2
            ;;
        --extra)
            EXTRA_DIRS="$2"
            shift 2
            ;;
        --watch)
            WATCH_MODE=true
            shift
            ;;
        *)
            DIRECTORIES+=("$1")
            shift
            ;;
    esac
done

# Validate arguments
if [ ${#DIRECTORIES[@]} -eq 0 ]; then
    echo "Error: No directories specified"
    echo "Usage: $0 [--withSchema schema.prisma] [--scanDir <dir>] [--outDir <dir>] [--extra dir1,dir2,...] [--watch] <dir1> <dir2> ..."
    exit 1
fi

# If no scan directory specified, use the first directory
if [ -z "$SCAN_DIR" ]; then
    SCAN_DIR="${DIRECTORIES[0]}"
fi

# Check if scan directory exists
if [ ! -d "$SCAN_DIR" ]; then
    echo "Error: Scan directory '$SCAN_DIR' not found or not accessible"
    exit 1
fi

# Create output directory
mkdir -p "$OUTPUT_DIR"
echo "Output files will be saved to: $OUTPUT_DIR"

# Log extra directories if specified
if [ -n "$EXTRA_DIRS" ]; then
    echo "Will search for related files in: $EXTRA_DIRS"
fi

# Create modified catFiles wrapper function that adds case-insensitive support
catFilesWithCaseSupport() {
    local grep_pattern="$1"
    shift
    
    # If --withSchema is provided, create a temporary wrapper script
    if [[ "$*" == *"--withSchema"* ]]; then
        # Create temporary wrapper script
        local tmp_script=$(mktemp)
        chmod +x "$tmp_script"
        
        # Write wrapper script that adds case-insensitive support
        cat > "$tmp_script" << 'EOF'
#!/usr/bin/env bash

# Parse arguments to find grep pattern and schema file
GREP_PATTERN=""
SCHEMA_FILE=""
OTHER_ARGS=()

while [[ $# -gt 0 ]]; do
    case "$1" in
        --grep)
            GREP_PATTERN="$2"
            OTHER_ARGS+=("$1" "$2")
            shift 2
            ;;
        --withSchema)
            SCHEMA_FILE="$2"
            OTHER_ARGS+=("$1" "$2")
            shift 2
            ;;
        *)
            OTHER_ARGS+=("$1")
            shift
            ;;
    esac
done

# If both grep pattern and schema file are provided, handle case-insensitive lookups
if [[ -n "$GREP_PATTERN" && -n "$SCHEMA_FILE" ]]; then
    # Extract base name (without any extension)
    BASE_NAME=$(echo "$GREP_PATTERN" | cut -d '.' -f1)
    
    # Check if schema file exists
    if [[ ! -f "$SCHEMA_FILE" ]]; then
        echo "Error: Schema file not found: $SCHEMA_FILE"
        exit 1
    fi
    
    # Create a modified version of the schema file with lowercase model names for comparison
    TMP_SCHEMA=$(mktemp)
    
    # Extract all model names from schema and create case-insensitive grep pattern
    MODEL_PATTERN=""
    while read -r line; do
        if [[ "$line" =~ ^model[[:space:]]+ ]]; then
            # Extract model name
            model_name=$(echo "$line" | sed -E 's/^model[[:space:]]+([a-zA-Z0-9_]+).*/\1/')
            
            # Check if base name might match this model (case-insensitive)
            if [[ "${model_name,,}" == "${BASE_NAME,,}" ]]; then
                echo "Found matching model: $model_name for base name: $BASE_NAME (case-insensitive match)"
                
                # Modify grep pattern to include both original case and this model case
                if [[ -z "$MODEL_PATTERN" ]]; then
                    MODEL_PATTERN="$GREP_PATTERN|${model_name}"
                else
                    MODEL_PATTERN="$MODEL_PATTERN|${model_name}"
                fi
            fi
        fi
    done < "$SCHEMA_FILE"
    
    # If we found model matches, use the enhanced pattern
    if [[ -n "$MODEL_PATTERN" ]]; then
        # Call original catFiles with expanded pattern
        catFiles --grep "$MODEL_PATTERN" "${OTHER_ARGS[@]}"
    else
        # No matches found, use original pattern
        catFiles "${OTHER_ARGS[@]}"
    fi
    
    # Clean up
    rm -f "$TMP_SCHEMA"
else
    # Call original catFiles with all arguments
    catFiles "${OTHER_ARGS[@]}"
fi
EOF
        
        # Call our wrapper script
        "$tmp_script" --grep "$grep_pattern" "$@"
        local result=$?
        
        # Clean up
        rm -f "$tmp_script"
        return $result
    else
        # No schema, just call original catFiles
        catFiles --grep "$grep_pattern" "$@"
    fi
}

# Function to get base name from a file path
get_base_name() {
    local file_path="$1"
    local file_name=$(basename "$file_path")
    echo "${file_name%.*}"  # Remove extension
}

# Process all files (used for initial run and full reprocessing)
process_all_files() {
    # Count and track files for summary
    SUCCESSFUL=0
    FAILED=0
    PROCESSED=0

    # Get list of files to process
    BASENAMES=()
    for file in "$SCAN_DIR"/*; do
        if [[ -f "$file" ]]; then
            baseName=$(basename "$file" | cut -d '.' -f1)
            BASENAMES+=("$baseName")
        fi
    done

    echo "Found ${#BASENAMES[@]} base names to process in $SCAN_DIR"

    # Process each base name
    for baseName in "${BASENAMES[@]}"; do
        ((PROCESSED++))
        outputFile="$OUTPUT_DIR/${baseName}-code.ts"
        
        echo "[$PROCESSED/${#BASENAMES[@]}] Processing: $baseName"
        
        # Add header with metadata
        {
            echo "// Generated by catAllFiles on $(date)"
            echo "// Base name: $baseName"
            echo "// Directories scanned: ${DIRECTORIES[*]}"
            echo "// Schema file: ${SCHEMA_FILE:-None}"
            echo "// Extra directories: ${EXTRA_DIRS:-None}"
            echo ""
            
            if [[ -n "$SCHEMA_FILE" && -n "$EXTRA_DIRS" ]]; then
                catFilesWithCaseSupport "$baseName" --withSchema "$SCHEMA_FILE" --extra "$EXTRA_DIRS" "${DIRECTORIES[@]}"
            elif [[ -n "$SCHEMA_FILE" ]]; then
                catFilesWithCaseSupport "$baseName" --withSchema "$SCHEMA_FILE" "${DIRECTORIES[@]}"
            elif [[ -n "$EXTRA_DIRS" ]]; then
                catFiles --grep "$baseName" --extra "$EXTRA_DIRS" "${DIRECTORIES[@]}"
            else
                catFiles --grep "$baseName" "${DIRECTORIES[@]}"
            fi
        } > "$outputFile"
        
        # Check if file contains actual content beyond the header (6 lines with the new extra dirs info)
        if [[ $(wc -l < "$outputFile") -gt 6 ]]; then
            echo "‚úÖ Processed $baseName -> $outputFile"
            ((SUCCESSFUL++))
        else
            echo "‚ùå No matching content found for $baseName"
            rm "$outputFile"  # Remove empty files
            ((FAILED++))
        fi
    done

    echo ""
    echo "Processing complete:"
    echo "- Total processed: $PROCESSED"
    echo "- Successful: $SUCCESSFUL"
    echo "- No content found: $FAILED"
    echo "- Output location: $OUTPUT_DIR"
}

# Function to detect which base name a file corresponds to
get_base_name_for_file() {
    local file="$1"
    local file_basename=$(basename "$file")
    
    # First check if this is a file from scan directory - direct match
    if [[ "$file" == "$SCAN_DIR"/* ]]; then
        echo "${file_basename%.*}" | cut -d '.' -f1
        return 0
    fi
    
    # Try exact matches on base names we know
    for base in "${ALL_BASENAMES[@]}"; do
        if [[ "$file_basename" == "$base".* || "$file_basename" == *"$base"* ]]; then
            echo "$base"
            return 0
        fi
    done
    
    # No match found
    return 1
}

# Run initial processing
process_all_files

# If watch mode is enabled, continue watching for changes
if [ "$WATCH_MODE" = true ]; then
    echo ""
    echo "üîç Watch mode enabled. Monitoring directories for changes..."
    echo "Press Ctrl+C to stop watching."
    
    # Build directory list to watch
    WATCH_DIRS=("${DIRECTORIES[@]}")
    if [[ -n "$SCHEMA_FILE" ]]; then
        SCHEMA_DIR=$(dirname "$SCHEMA_FILE")
        WATCH_DIRS+=("$SCHEMA_DIR")
    fi
    
    # Add extra directories to watch list if specified
    if [[ -n "$EXTRA_DIRS" ]]; then
        IFS=',' read -ra EXTRA_DIRS_ARRAY <<< "$EXTRA_DIRS"
        for extraDir in "${EXTRA_DIRS_ARRAY[@]}"; do
            WATCH_DIRS+=("$extraDir")
        done
    fi
    
    # Remove duplicates
    WATCH_DIRS=($(printf "%s\n" "${WATCH_DIRS[@]}" | sort -u))
    
    # Get all base names for reference
    ALL_BASENAMES=()
    for file in "$SCAN_DIR"/*; do
        if [[ -f "$file" ]]; then
            baseName=$(basename "$file" | cut -d '.' -f1)
            ALL_BASENAMES+=("$baseName")
        fi
    done
    
    echo "Found ${#ALL_BASENAMES[@]} base names for watch mode"
    
    # Print directories being watched
    echo "Watching directories:"
    for dir in "${WATCH_DIRS[@]}"; do
        echo "- $dir"
    done
    
    # Set last run time
    LAST_RUN=$(date +%s)
    MIN_INTERVAL=2  # Minimum seconds between runs
    
    # Store file modification times
    declare -A FILE_TIMES
    
    # Initial scan to build baseline
    echo "Building initial file index..."
    total_files=0
    for dir in "${WATCH_DIRS[@]}"; do
        if [[ -d "$dir" ]]; then
            while read -r file; do
                if [[ -f "$file" ]]; then
                    # Get modification time
                    mod_time=$(stat -f "%m" "$file" 2>/dev/null || stat -c "%Y" "$file" 2>/dev/null)
                    FILE_TIMES["$file"]=$mod_time
                    ((total_files++))
                fi
            done < <(find "$dir" -type f -not -path "*/\.*" -not -path "*/node_modules/*" 2>/dev/null || echo "")
        fi
    done
    
    echo "Watching $total_files files for changes (polling every 1 second)..."
    
    # Process a single base name when change detected
    process_base_name() {
        local baseName="$1"
        local outputFile="$OUTPUT_DIR/${baseName}-code.ts"
        
        echo "Processing: $baseName"
        
        # Add header with metadata
        {
            echo "// Generated by catAllFiles on $(date)"
            echo "// Base name: $baseName"
            echo "// Directories scanned: ${DIRECTORIES[*]}"
            echo "// Schema file: ${SCHEMA_FILE:-None}"
            echo "// Extra directories: ${EXTRA_DIRS:-None}"
            echo ""
        
            if [[ -n "$SCHEMA_FILE" && -n "$EXTRA_DIRS" ]]; then
                catFilesWithCaseSupport "$baseName" --withSchema "$SCHEMA_FILE" --extra "$EXTRA_DIRS" "${DIRECTORIES[@]}"
            elif [[ -n "$SCHEMA_FILE" ]]; then
                catFilesWithCaseSupport "$baseName" --withSchema "$SCHEMA_FILE" "${DIRECTORIES[@]}"
            elif [[ -n "$EXTRA_DIRS" ]]; then
                catFiles --grep "$baseName" --extra "$EXTRA_DIRS" "${DIRECTORIES[@]}"
            else
                catFiles --grep "$baseName" "${DIRECTORIES[@]}"
            fi
        } > "$outputFile"
        
        # Check if file contains actual content beyond the header (6 lines with extra dirs info)
        if [[ $(wc -l < "$outputFile") -gt 6 ]]; then
            echo "‚úÖ Processed $baseName -> $outputFile"
            return 0
        else
            echo "‚ùå No matching content found for $baseName"
            rm "$outputFile"  # Remove empty files
            return 1
        fi
    }
    
    # Polling loop
    while true; do
        sleep 1
        changed=false
        changed_files=()
        
        for dir in "${WATCH_DIRS[@]}"; do
            if [[ -d "$dir" ]]; then
                while read -r file; do
                    if [[ -f "$file" ]]; then
                        # Get current modification time
                        current_time=$(stat -f "%m" "$file" 2>/dev/null || stat -c "%Y" "$file" 2>/dev/null)
                        
                        # If file is new or modified
                        if [[ -z "${FILE_TIMES[$file]}" || "${FILE_TIMES[$file]}" != "$current_time" ]]; then
                            changed=true
                            changed_files+=("$file")
                            FILE_TIMES["$file"]=$current_time
                        fi
                    fi
                done < <(find "$dir" -type f -not -path "*/\.*" -not -path "*/node_modules/*" 2>/dev/null || echo "")
            fi
        done
        
        # Process changed files
        if [[ "$changed" == true ]]; then
            CURRENT_TIME=$(date +%s)
            if (( CURRENT_TIME - LAST_RUN >= MIN_INTERVAL )); then
                echo ""
                echo "üîÑ Changes detected at $(date '+%H:%M:%S')!"
                
                # Show changed files (limit to first 3 for brevity)
                max_display=$(( ${#changed_files[@]} > 3 ? 3 : ${#changed_files[@]} ))
                for ((i=0; i<max_display; i++)); do
                    echo "- ${changed_files[$i]}"
                done
                
                if [[ ${#changed_files[@]} -gt 3 ]]; then
                    echo "- ...and $((${#changed_files[@]} - 3)) more files"
                fi
                
                # Track which base names have been processed
                processed_bases=()
                processed_count=0
                
                # Process each changed file
                for file in "${changed_files[@]}"; do
                    base_name=$(get_base_name_for_file "$file")
                    
                    # Skip if we can't determine the base name
                    if [[ -z "$base_name" ]]; then
                        continue
                    fi
                    
                    # Skip if we've already processed this base name
                    if [[ " ${processed_bases[*]} " == *" $base_name "* ]]; then
                        continue
                    fi
                    
                    # Process the file
                    echo "üîç File change relates to base name: $base_name"
                    if process_base_name "$base_name"; then
                        processed_bases+=("$base_name")
                        ((processed_count++))
                    fi
                done
                
                # If no files were processed, notify the user
                if [[ $processed_count -eq 0 ]]; then
                    echo "‚ö†Ô∏è No relevant files to process. Change might not be related to any known base names."
                else
                    echo "‚úÖ Processed $processed_count base name(s)"
                fi
                
                LAST_RUN=$(date +%s)
                echo ""
                echo "Watching for more changes... (Press Ctrl+C to stop)"
            fi
        fi
    done
fi