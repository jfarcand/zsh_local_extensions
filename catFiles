#!/usr/bin/env bash

# -----------------------------------------------------------------------------
# catFiles: A Bash script to concatenate and display files with optional schema lookup
# -----------------------------------------------------------------------------
# Usage:
#   catFiles [--root path] [--includes ext1,ext2] [--excludes dir1,dir2] 
#            [--extra ext1,ext2] [--extensions ext1,ext2] [--grep pattern] 
#            [--withSchema schema.prisma] [paths...]
#
# Description:
#   This script processes files, concatenating and displaying their contents 
#   based on specified criteria. It supports filtering by file extensions, 
#   excluding directories, and searching for filenames containing a specific 
#   string (via --grep). It can also include relevant Prisma model definitions 
#   from a schema file if `--withSchema` is used.
#
# Options:
#   --root path         Set a root directory to prepend to file paths.
#   --includes ext1,ext2
#                       Include only specific file extensions (comma-separated).
#   --excludes dir1,dir2
#                       Exclude specific directories from processing.
#   --extra ext1,ext2   Include additional related files (e.g., inputs, types).
#   --extensions ext1,ext2
#                       Set allowed file extensions (default: .ts, .tsx).
#   --grep pattern      Filter filenames containing a specific pattern.
#   --withSchema schema.prisma
#                       Look up corresponding model definitions from schema.
#   paths...            Files or directories to process.
#
# -----------------------------------------------------------------------------

# Check if any arguments were provided
if [ $# -eq 0 ]; then
    echo "Usage: $0 [--root path] [--includes ext1,ext2] [--excludes dir1,dir2] [--extra ext1,ext2] [--extensions ext1,ext2] [--grep pattern] [--withSchema schema.prisma] [paths...]"
    exit 1
fi

# Initialize variables
ROOT=""
INCLUDES=()
EXCLUDE_DIRS=()
EXTENSIONS=(".ts" ".tsx")  # Default to .ts and .tsx files
EXTRA_PATHS=() # Extra paths to search for related files
PATHS=()
GREP_PATTERN=""  # Store grep pattern
SCHEMA_FILE=""  # Store schema file path
PROCESSED_FILES=() # Track processed files to avoid duplicates
FOUND_MAIN_FILES=() # Track files found by grep to process extras for

# Create a temporary file to track processed models
MODEL_TRACKER=$(mktemp)
trap 'rm -f "$MODEL_TRACKER"' EXIT  # Remove temp file on exit

# Parse arguments
while [[ $# -gt 0 ]]; do
    case "$1" in
        --root)
            ROOT="$2"
            shift 2
            ;;
        --includes)
            IFS=',' read -ra INCLUDES <<< "$2"
            shift 2
            ;;
        --excludes)
            IFS=',' read -ra EXCLUDE_DIRS <<< "$2"
            shift 2
            ;;
        --extra)
            IFS=',' read -ra EXTRA_PATHS <<< "$2"
            shift 2
            ;;
        --extensions)
            IFS=',' read -ra EXTENSIONS <<< "$2"
            shift 2
            ;;
        --grep)
            GREP_PATTERN="$2"
            shift 2
            ;;
        --withSchema)
            SCHEMA_FILE="$2"
            shift 2
            ;;
        *)
            PATHS+=("$1")
            shift
            ;;
    esac
done

# Function to check if a model has already been processed
is_model_processed() {
    local modelName="$1"
    grep -q "^${modelName}$" "$MODEL_TRACKER"
    return $?
}

# Function to mark a model as processed
mark_model_processed() {
    local modelName="$1"
    echo "$modelName" >> "$MODEL_TRACKER"
}

# Function to find model definition in schema.prisma
find_model_in_schema() {
    local modelName="$1"
    local schema="$2"

    # Check if this model has already been processed
    if is_model_processed "$modelName"; then
        return  # Skip if already processed
    fi

    if [[ -f "$schema" ]]; then
        local modelDefinition=$(awk -v model="model $modelName {" '
        $0 ~ model { capture=1 } capture;
        capture && /^}/ { capture=0; print ""; exit }
        ' "$schema")
        
        if [[ -n "$modelDefinition" ]]; then
            # Only mark as processed if we actually found the model
            mark_model_processed "$modelName"
            echo "$modelDefinition"
        fi
    fi
}

# Function to check if path should be excluded
is_excluded() {
    local file="$1"
    for exclude in "${EXCLUDE_DIRS[@]}"; do
        if [[ "$file" == "$exclude"* ]]; then
            return 0
        fi
    done
    return 1
}

# Function to check if file has a valid extension
has_valid_extension() {
    local file="$1"
    for ext in "${EXTENSIONS[@]}"; do
        if [[ "$file" == *"$ext" ]]; then
            return 0
        fi
    done
    return 1
}

# Function to filter files by grep pattern
matches_grep_pattern() {
    local file="$1"
    if [[ -n "$GREP_PATTERN" ]]; then
        if [[ "$file" != *"$GREP_PATTERN"* ]]; then
            return 1  # File doesn't match grep pattern
        fi
    fi
    return 0  # No grep pattern or file matches
}

# Function to check if a file has already been processed
is_file_processed() {
    local file="$1"
    for processed in "${PROCESSED_FILES[@]}"; do
        if [[ "$processed" == "$file" ]]; then
            return 0  # Already processed
        fi
    done
    return 1  # Not processed yet
}

# Function to extract base name without path and extension
get_base_name() {
    local file="$1"
    # Get just filename without path
    local filename=$(basename "$file")
    # Extract everything up to first dot
    local base="${filename%%.*}"
    echo "$base"
}

# Function to process a single file
process_file() {
    local file="$1"
    local baseName=$(basename "$file" | cut -d '.' -f1)
    
    # Skip if file has already been processed
    if is_file_processed "$file"; then
        return
    fi
    
    # Add to processed files list
    PROCESSED_FILES+=("$file")

    if [ -f "$file" ] && ! is_excluded "$file" && has_valid_extension "$file" && matches_grep_pattern "$file"; then
        # Add to found main files list if it matches grep pattern
        if [[ -n "$GREP_PATTERN" ]]; then
            FOUND_MAIN_FILES+=("$file")
        fi
        
        # Include Prisma model if --withSchema is provided
        if [[ -n "$SCHEMA_FILE" ]]; then
            local capitalizedBaseName="$(tr '[:lower:]' '[:upper:]' <<< "${baseName:0:1}")${baseName:1}"
            local modelDefinition=$(find_model_in_schema "$capitalizedBaseName" "$SCHEMA_FILE")

            if [[ -n "$modelDefinition" ]]; then
                echo "$modelDefinition"
            fi
        fi

        echo "// $file"
        cat "$file"
        echo ""
    fi
}

# Function to process related files from extra paths
process_related_files() {
    local mainFile="$1"
    
    # Get the normalized base name
    local baseFileName=$(get_base_name "$mainFile")
    
    # Create lowercase and capitalized versions for searching
    local lowercaseBase=$(echo "$baseFileName" | tr '[:upper:]' '[:lower:]')
    local capitalizedBase="$(tr '[:lower:]' '[:upper:]' <<< ${lowercaseBase:0:1})${lowercaseBase:1}"
    
    # Look for files with lowercase or capitalized versions in all extra paths
    for extraPath in "${EXTRA_PATHS[@]}"; do
        # Find files matching lowercase pattern
        while IFS= read -r extraFile; do
            if [[ -n "$extraFile" ]] && [[ -f "$extraFile" ]] && ! is_file_processed "$extraFile"; then
                PROCESSED_FILES+=("$extraFile")
                echo "// $extraFile (related file - lowercase match)"
                cat "$extraFile"
                echo ""
            fi
        done < <(find "$extraPath" -type f -name "${lowercaseBase}.*" 2>/dev/null)
        
        # Find files matching capitalized pattern
        while IFS= read -r extraFile; do
            if [[ -n "$extraFile" ]] && [[ -f "$extraFile" ]] && ! is_file_processed "$extraFile"; then
                PROCESSED_FILES+=("$extraFile")
                echo "// $extraFile (related file - capitalized match)"
                cat "$extraFile"
                echo ""
            fi
        done < <(find "$extraPath" -type f -name "${capitalizedBase}.*" 2>/dev/null)
        
        # Try to be even more flexible if other attempts failed
        # Extract meaningful part from compound filenames (e.g., PeuplementStore -> Peuplement)
        if [[ "$baseFileName" == *"Store" || "$baseFileName" == *"Service" || "$baseFileName" == *"Controller" || "$baseFileName" == *"Resolver" ]]; then
            local strippedBase="${baseFileName%%Store*}"
            strippedBase="${strippedBase%%Service*}"
            strippedBase="${strippedBase%%Controller*}"
            strippedBase="${strippedBase%%Resolver*}"
            
            # Create lowercase and capitalized versions of the stripped base
            local lowercaseStripped=$(echo "$strippedBase" | tr '[:upper:]' '[:lower:]')
            local capitalizedStripped="$(tr '[:lower:]' '[:upper:]' <<< ${lowercaseStripped:0:1})${lowercaseStripped:1}"
            
            # Search for both versions if they differ from the original searches
            if [[ "$lowercaseStripped" != "$lowercaseBase" ]]; then
                while IFS= read -r extraFile; do
                    if [[ -n "$extraFile" ]] && [[ -f "$extraFile" ]] && ! is_file_processed "$extraFile"; then
                        PROCESSED_FILES+=("$extraFile")
                        echo "// $extraFile (related file - stripped lowercase match)"
                        cat "$extraFile"
                        echo ""
                    fi
                done < <(find "$extraPath" -type f -name "${lowercaseStripped}.*" 2>/dev/null)
            fi
            
            if [[ "$capitalizedStripped" != "$capitalizedBase" ]]; then
                while IFS= read -r extraFile; do
                    if [[ -n "$extraFile" ]] && [[ -f "$extraFile" ]] && ! is_file_processed "$extraFile"; then
                        PROCESSED_FILES+=("$extraFile")
                        echo "// $extraFile (related file - stripped capitalized match)"
                        cat "$extraFile"
                        echo ""
                    fi
                done < <(find "$extraPath" -type f -name "${capitalizedStripped}.*" 2>/dev/null)
            fi
        fi
    done
}

# Print initial message
if [[ -n "$SCHEMA_FILE" ]]; then
    echo "// Processing files with model tracking to prevent duplicate model definitions"
    echo ""
fi

# Print info about --extra usage
if [[ ${#EXTRA_PATHS[@]} -gt 0 ]]; then
    if [[ -n "$GREP_PATTERN" ]]; then
        echo "// Using both --grep and --extra: will find files with \"$GREP_PATTERN\" first, then process related files"
    else
        echo "// Will look for related files in extra paths: ${EXTRA_PATHS[*]}"
    fi
    echo ""
fi

# Process all files
for path in "${PATHS[@]}"; do
    if [ -f "$path" ]; then
        process_file "$path"
    elif [ -d "$path" ]; then
        # Use while loop with process substitution to avoid subshell issues
        while IFS= read -r file; do
            process_file "$file"
        done < <(find "$path" -type f -print)
    fi
done

# If grep and extra are both used, now process related files for all found main files
if [[ -n "$GREP_PATTERN" && ${#EXTRA_PATHS[@]} -gt 0 ]]; then
    for mainFile in "${FOUND_MAIN_FILES[@]}"; do
        process_related_files "$mainFile"
    done
fi

# Print summary
if [[ -n "$SCHEMA_FILE" ]]; then
    MODEL_COUNT=$(wc -l < "$MODEL_TRACKER")
    if [ "$MODEL_COUNT" -gt 0 ]; then
        echo "// Processed $MODEL_COUNT unique models: $(cat "$MODEL_TRACKER" | tr '\n' ' ')"
    fi
fi

echo "// Processed ${#PROCESSED_FILES[@]} files total"gs